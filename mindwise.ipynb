{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCs6bi/RVUSmJNvyQ9VcGH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pratayyy/MindWise/blob/main/mindwise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iR3_07CmtwJo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import cv2\n",
        "import gym\n",
        "import random\n",
        "from gym import spaces\n",
        "from google.colab import widgets\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.offsetbox import OffsetImage, AnnotationBbox"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum\n",
        "\n",
        "MAX_TIMESTEPS = 300\n",
        "GAMMA = 0.99\n",
        "ALPHA = 0.3\n",
        "EPSILON = 1.0\n",
        "EPISODES = 1000\n",
        "\n",
        "class Environment(Enum):\n",
        "  Deterministic = 1\n",
        "  Stochastic = 2\n",
        "\n",
        "class Agent(Enum):\n",
        "  QLearning = 1  \n",
        "  DoubleQLearning = 2\n"
      ],
      "metadata": {
        "id": "FNGL1dN-1BUq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass\n",
        "@dataclass\n",
        "class LearningParameter:\n",
        "  # Default values of learning parameters\n",
        "    epsilon: float = EPSILON \n",
        "    gamma: float = GAMMA\n",
        "    alpha: float = ALPHA\n",
        "    max_timesteps: int = MAX_TIMESTEPS\n",
        "    episodes: int = EPISODES\n",
        "    epsilon_decay:float = 0.99\n",
        "@dataclass\n",
        "class Experience:\n",
        "    state: int = None \n",
        "    action: int = None\n",
        "    next_state: int = None\n",
        "    reward: float = None   \n",
        "    done: bool = None   "
      ],
      "metadata": {
        "id": "PNIWdc3D3F6H"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GridEnvironment(gym.Env):\n",
        "    metadata = { 'render.modes': [] }\n",
        "    ROWS = 9\n",
        "    COLS = 9\n",
        "\n",
        "\n",
        "    NO_OF_ACTIONS = 8\n",
        "\n",
        "    def remove_points(self,arr:np.ndarray, points:list):\n",
        "          arr_list = list(arr)\n",
        "          for i in range(len(points)):\n",
        "             for j in range(len(arr)):\n",
        "               if(all(list(arr[j]) == points[i])):\n",
        "                 arr_list.pop(j)\n",
        "          return np.asarray(arr_list)\n",
        "  \n",
        "\n",
        "    def set_artifact_positions(self,environment:Environment):\n",
        "        self.agent_pos = np.asarray([0, 0])\n",
        "        self.goal_pos = np.asarray([8, 8])\n",
        "        self.demon_pos = np.asarray([4, 4])\n",
        "        stochastic_toxin_pos = [[[3,2], [7,6], [2,7]],[[4,3],[8,5],[3,6]]] \n",
        "        stochastic_hp_pos = [[[4,2], [8,6], [3,7]],[[3,3],[8,4],[3,5]]]\n",
        "\n",
        "\n",
        "        if(environment == Environment.Deterministic ):\n",
        "          self.toxin_pos = np.asarray([[3,2], [7,6], [2,7]])\n",
        "          self.hp_pos = np.asarray([[1,1], [3,4], [4,7]])\n",
        "        else:\n",
        "          self.toxin_pos = np.asarray(random.choices(stochastic_toxin_pos, weights=(10, 90), k=1)[0])  \n",
        "          self.hp_pos = np.asarray(random.choices(stochastic_hp_pos, weights=(10, 90), k=1)[0])\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "    def __init__(self, environment_type=Environment.Deterministic, render_trace = False, parameter=LearningParameter()):\n",
        "        self.environment_type = environment_type\n",
        "        self.observation_space = spaces.Discrete(self.ROWS * self.COLS)\n",
        "        self.action_space = spaces.Discrete(self.NO_OF_ACTIONS)\n",
        "        self.max_timesteps = MAX_TIMESTEPS\n",
        "        self.timesteps = 0\n",
        "        self.render_trace = render_trace\n",
        "\n",
        "        # Create a map of coordinates and state\n",
        "        self.coordinates_state_mapping = {}\n",
        "        for i in range(self.ROWS):\n",
        "            for j in range(self.COLS):\n",
        "                self.coordinates_state_mapping[f'{np.asarray([j, i])}'] = i * self.COLS + j\n",
        "                \n",
        "    def reset(self):\n",
        "        self.timestep = 0\n",
        "        self.set_artifact_positions(self.environment_type)\n",
        "\n",
        "        # return the agent_pos coordinates\n",
        "        observation = self.coordinates_state_mapping[f'{self.agent_pos}']\n",
        "        return observation\n",
        "\n",
        "    def step(self, action):\n",
        "      \n",
        "        #Actions\n",
        "        if action == 0:\n",
        "          self.agent_pos[0] += 1 # Agent moves right\n",
        "        elif action == 1:\n",
        "          self.agent_pos[0] -= 1 # Agent moves left\n",
        "        elif action == 2:\n",
        "          self.agent_pos[1] += 1 # Agent moves up\n",
        "        elif action == 3:\n",
        "          self.agent_pos[1] -= 1 # Agent moves down\n",
        "        elif action == 4:        # Agent moves down_right\n",
        "          self.agent_pos[0] += 1 \n",
        "          self.agent_pos[1] += 1\n",
        "        elif action == 5:        # Agent moves top_left\n",
        "          self.agent_pos[0] -= 1\n",
        "          self.agent_pos[1] -= 1\n",
        "        elif action == 6:        # Agent moves top_right\n",
        "          self.agent_pos[0] += 1\n",
        "          self.agent_pos[1] -= 1\n",
        "        elif action == 7:        # Agent moves down_left\n",
        "          self.agent_pos[0] -= 1  \n",
        "          self.agent_pos[1] += 1  \n",
        "            \n",
        "\n",
        "        # Clipping\n",
        "        self.agent_pos = np.clip(self.agent_pos, a_min=[0, 0],\n",
        "                                 a_max=[self.ROWS - 1, self.COLS - 1])\n",
        "      \n",
        "        observation = self.coordinates_state_mapping[f'{np.asarray(self.agent_pos)}']\n",
        "           \n",
        "\n",
        "        #Reward assignment\n",
        "        reward = -1\n",
        "        toxin_reward = -200\n",
        "        hp_reward = 200\n",
        "        goal_reward = 2000\n",
        "        demon_reward = -2000\n",
        "        \n",
        "              \n",
        "\n",
        "        done = False\n",
        "\n",
        "        # Render is called here to ensure tile-agent interaction visualisation is preserved\n",
        "        # (Artifacts once popped out of the array will remove the \"interaction\" for visualisation logic to use)\n",
        "        if self.render_trace:\n",
        "          with output_grid.output_to(0, 0):\n",
        "            output_grid.clear_cell()\n",
        "            self.render()\n",
        "\n",
        "       \n",
        "       # Terminate if goal is attained\n",
        "        if (self.agent_pos == self.goal_pos).all():\n",
        "            reward += goal_reward\n",
        "            done = True\n",
        "\n",
        "       # Terminate if interacts with demon\n",
        "        elif(self.agent_pos == self.demon_pos).all():\n",
        "            reward += demon_reward \n",
        "            done = True   \n",
        "      \n",
        "        # if hp_pos is encountered, collect reward and pop the hp from hp_pos\n",
        "        elif any(((hp_pos == self.agent_pos).all() for hp_pos in self.hp_pos)):      \n",
        "          for i in range(len(self.hp_pos)):\n",
        "              if (self.agent_pos == self.hp_pos[i]).all():\n",
        "                reward += hp_reward\n",
        "                self.hp_pos = self.remove_points(self.hp_pos,[self.hp_pos[i]]) \n",
        "                break \n",
        "                \n",
        "\n",
        "        # if toxin_pos is encountered, collect reward and pop the hp from toxin_pos\n",
        "        elif any(((toxin_pos == self.agent_pos).all() for toxin_pos in self.toxin_pos)):          \n",
        "          for i in range(len(self.toxin_pos)):\n",
        "              if (self.agent_pos == self.toxin_pos[i]).all():\n",
        "                reward += toxin_reward\n",
        "                self.toxin_pos = self.remove_points(self.toxin_pos,[self.toxin_pos[i]])      \n",
        "                break\n",
        "\n",
        "        # Ensure agent is motivated to optimize moves\n",
        "        else:\n",
        "          reward-=1        \n",
        "                  \n",
        "\n",
        "        self.timestep += 1\n",
        "\n",
        "        if (self.timestep >= self.max_timesteps):\n",
        "          done = True\n",
        "\n",
        "        info = {}\n",
        "       \n",
        "\n",
        "        return observation, reward, done, info\n",
        "\n",
        "    def render(self, mode='human', plot=False):\n",
        "        \"\"\"This method renders the environment.\n",
        "\n",
        "        :param str mode: 'human' renders to the current display or terminal and returns nothing.\n",
        "        :param bool plot: Boolean indicating whether we show a plot or not. If False, the method returns a resized NumPy\n",
        "                     array representation of the environment to be used as the state. If True it plots the environment.\n",
        "\n",
        "        :returns arr preprocessed_image: Grayscale NumPy array representation of the environment.\"\"\"\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        ax.set_xlim(0, 9)\n",
        "        ax.set_ylim(0, 9)\n",
        "\n",
        "        if(self.environment_type == Environment.Deterministic):\n",
        "          ax.set_title('Deterministic Learning Env')\n",
        "        else:\n",
        "          ax.set_title('Stochastic Learning Env') \n",
        "\n",
        "        def plot_image(plot_pos):\n",
        "            \"\"\"This is a helper function to render the environment. It checks which objects are in a particular\n",
        "            position on the grid and renders the appropriate image.\n",
        "\n",
        "            :param arr plot_pos: Co-ordinates of the grid position which needs to be rendered.\"\"\"\n",
        "\n",
        "            # Initially setting every object to not be plotted.\n",
        "            plot_agent, plot_hp, plot_goal, plot_toxin, plot_demon = \\\n",
        "                False, False, False, False, False\n",
        "\n",
        "            # Checking which objects need to be plotted by comparing their positions.\n",
        "            if np.array_equal(self.agent_pos, plot_pos):\n",
        "                plot_agent = True\n",
        "            if any(np.array_equal(self.hp_pos[i], plot_pos) for i in range(len(self.hp_pos))):\n",
        "                plot_hp = True\n",
        "        \n",
        "            if any(np.array_equal(self.toxin_pos[i], plot_pos) for i in range(len(self.toxin_pos))):\n",
        "                plot_toxin = True\n",
        "       \n",
        "            if np.array_equal(plot_pos, self.demon_pos):\n",
        "                plot_demon = True\n",
        "\n",
        "            if np.array_equal(plot_pos, self.goal_pos):\n",
        "                plot_goal = True    \n",
        "\n",
        "            # Plot for Agent.\n",
        "            if plot_agent and \\\n",
        "                    all(not item for item in\n",
        "                        [plot_hp, plot_goal, plot_toxin, plot_demon]):\n",
        "                agent = AnnotationBbox(OffsetImage(plt.imread('images/agent.png'), zoom=0.3),\n",
        "                                       np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(agent)\n",
        "\n",
        "          \n",
        "            # Plot for Toxin.\n",
        "            elif plot_toxin and \\\n",
        "                    all(not item for item in\n",
        "                        [plot_agent, plot_hp, plot_goal, plot_demon]):\n",
        "                toxin = AnnotationBbox(OffsetImage(plt.imread('images/toxin.png'), zoom=0.3),\n",
        "                                     np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(toxin)\n",
        "           \n",
        "            # Plot for HP.\n",
        "            elif plot_hp and \\\n",
        "                    all(not item for item in\n",
        "                        [plot_agent, plot_toxin, plot_goal, plot_demon]):\n",
        "                hp = AnnotationBbox(OffsetImage(plt.imread('images/hp.png'), zoom=0.3),\n",
        "                                     np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(hp)     \n",
        "\n",
        "            # Plot for Demon.\n",
        "            elif plot_demon and \\\n",
        "                    all(not item for item in\n",
        "                        [plot_agent, plot_hp, plot_goal, plot_toxin]):\n",
        "                demon = AnnotationBbox(OffsetImage(plt.imread('images/demon.png'), zoom=0.3),\n",
        "                                        np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(demon)\n",
        "\n",
        "            # Plot for Goal.\n",
        "            elif plot_goal and \\\n",
        "                    all(not item for item in\n",
        "                        [plot_agent, plot_hp, plot_demon, plot_toxin]):\n",
        "                goal = AnnotationBbox(OffsetImage(plt.imread('images/goal.png'), zoom=0.3),\n",
        "                                        np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(goal)    \n",
        "\n",
        "            # Plot for Agent and HP.\n",
        "            elif all( [plot_agent, plot_hp]) and \\\n",
        "                    not(all(\n",
        "                        [plot_goal, plot_toxin, plot_demon])):\n",
        "                agent_hp = AnnotationBbox(OffsetImage(plt.imread('images/agent_hp.png'), zoom=0.3),\n",
        "                                              np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(agent_hp)\n",
        "\n",
        "            # Plot for Agent and Toxin.\n",
        "            elif all(item for item in [plot_agent, plot_toxin]) and \\\n",
        "                    all(not item for item in\n",
        "                        [plot_hp, plot_goal, plot_demon]):\n",
        "                agent_toxin = AnnotationBbox(OffsetImage(plt.imread('images/agent_toxin.png'), zoom=0.3),\n",
        "                                           np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(agent_toxin)\n",
        "\n",
        "\n",
        "            # Plot for Agent and Demon.\n",
        "            elif all(item for item in [plot_agent, plot_demon]) and \\\n",
        "                    all(not item for item in\n",
        "                        [plot_goal, plot_toxin, plot_hp]):\n",
        "                agent_demon = AnnotationBbox(OffsetImage(plt.imread('images/agent_demon.png'),\n",
        "                                                          zoom=0.3), np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(agent_demon)\n",
        "\n",
        "            # Plot for Agent and Goal.\n",
        "            elif all(item for item in [plot_agent, plot_goal]) and \\\n",
        "                    all(not item for item in\n",
        "                        [plot_demon, plot_toxin, plot_hp]):\n",
        "                agent_goal = AnnotationBbox(OffsetImage(plt.imread('images/agent_goal.png'),\n",
        "                                                          zoom=0.3), np.add(plot_pos, [0.5, 0.5]), frameon=False)\n",
        "                ax.add_artist(agent_goal)    \n",
        "\n",
        "         \n",
        "        # Create a map of state and coordinates \n",
        "        state_coordinates_mapping = {}\n",
        "        for j in range(self.ROWS * self.COLS):\n",
        "            state_coordinates_mapping[j] = np.asarray(\n",
        "                [j % self.COLS, int(np.floor(j / self.COLS))])\n",
        "\n",
        "        # Rendering the images for all states.\n",
        "        for position in state_coordinates_mapping:\n",
        "            plot_image(state_coordinates_mapping[position])\n",
        "\n",
        "        plt.xticks([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
        "        plt.yticks([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
        "        plt.grid()  # Setting the plot to be of the type 'grid'.\n",
        "\n",
        "        if plot:  # Displaying the plot.\n",
        "            plt.show()\n",
        "        else:  # Returning the preprocessed image representation of the environment.\n",
        "            fig.canvas.draw()\n",
        "            img = np.array(fig.canvas.renderer.buffer_rgba())[:, :, :3]\n",
        "            width = 84 \n",
        "            height = 84\n",
        "            dim = (width, height)\n",
        "            # noinspection PyUnresolvedReferences\n",
        "            preprocessed_image = cv2.resize(img, dim, interpolation=cv2.INTER_AREA)\n",
        "            plt.show()\n",
        "            return preprocessed_image"
      ],
      "metadata": {
        "id": "M1R4HEXK3gLr"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}